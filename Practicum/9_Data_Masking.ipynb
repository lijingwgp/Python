{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review (2)\n",
    "\n",
    "Thanks for the update. It looks correct now so I'm accepting your project. Good luck.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Hi Jing. This is Soslan. As always I've added all my comments to new cells with different coloring.\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  If you did something great I'm using green color for my comment\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "If I want to give you advice or think that something can be improved, then I'll use yellow. This is an optional recommendation.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  If the topic requires some extra work so I can accept it then the color will be red\n",
    "</div>\n",
    "\n",
    "I have just one issue to the theoretical part. There was a mistake in your arguments when you looked at the angle between two vectors you forgot to consider their magnitudes, they are also small. I think you should use another reasoning. I left a comment for you. Good luck.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Information\n",
    "\n",
    "A insurance company wants to protect its clients' data. The task is to develop a data transforming algorithm that would make it hard to recover personal information from the transformed data. This is called data masking. We are also expected to prove that the algorithm works correctly. Additionally, the data should be protected in such a way that the quality of machine learning models doesn't suffer. Follow these steps to develop a new algorithm:\n",
    "- Construct a theoretical proof using properties of models and the given task;\n",
    "- Formulate an algorithm for this proof;\n",
    "- Check that the algorithm is working correctly when applied to real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Instruction\n",
    "\n",
    "1. Download and look into the data.\n",
    "2. Provide a theoretical proof based on the equation of linear regression. The features are multiplied by an invertible matrix. Show that the quality of the model is the same for both sets of parameters: the original features and the features after multiplication. How are the weight vectors from MSE minimums for these models related?\n",
    "3. State an algorithm for data transformation to solve the task. Explain why the linear regression quality won't change based on the proof above.\n",
    "4. Program your algorithm using matrix operations. Make sure that the quality of linear regression from sklearn is the same before and after transformation. Use the R2 metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Family members</th>\n",
       "      <th>Insurance benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age   Salary  Family members  Insurance benefits\n",
       "0       1  41.0  49600.0               1                   0\n",
       "1       0  46.0  38000.0               1                   1\n",
       "2       0  29.0  21000.0               0                   0\n",
       "3       0  21.0  41700.0               2                   0\n",
       "4       1  28.0  26100.0               0                   0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data = pd.read_csv('/datasets/insurance_us.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Correct start. Data was opened correctly.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a theoretical proof based on the equation of linear regression. \n",
    "Provide a theoretical proof based on the equation of linear regression. The following equations will form a basis of our analysis today. Let's choose MSE as our loss function. To minimize it, we will use it in the context of linear regression. Thus we have the following formula:\n",
    "\n",
    "    w = arg_w min MSE(Xw, y)\n",
    "    \n",
    "The minimum MSE is obtained when the weights are equal to this value:\n",
    "\n",
    "    w = (X.t * X)^-1 * X.t * y\n",
    "    \n",
    "where \n",
    "- the transposed feature matrix is multiplied by itself;\n",
    "- the matrix inverse to the result is calculated;\n",
    "- the inverse matrix is multiplied by the transposed feature matrix;\n",
    "- the result is multiplied by the vector of the target feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The features are multiplied by an invertible matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature matrix\n",
    "\n",
    "matrix_original = data.drop('Insurance benefits', axis=1).values\n",
    "matrix_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find a random invertible matrix of corresponding size\n",
    "\n",
    "tol = 1e-12\n",
    "while True:\n",
    "   A = np.random.rand(matrix_original.shape[1], matrix_original.shape[0]);\n",
    "   B = A @ A.T;\n",
    "   err = np.abs(B @ np.linalg.inv(B) - np.identity(matrix_original.shape[1]))\n",
    "   if err.all() < tol:\n",
    "      break\n",
    "\n",
    "# feature matrix multiplied by an invertible matrix\n",
    "\n",
    "matrix_new = matrix_original @ B\n",
    "matrix_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Correct</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that the quality of the model is the same for both sets of parameters: the original features and the features after multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.43854686e-02,  2.33356224e-02, -1.17739038e-05, -4.55168125e-02])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-6.54841463e-05,  9.01471566e-05,  3.56435998e-05, -7.15728779e-05])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine the set of parameters for the original features\n",
    "\n",
    "y = data['Insurance benefits'].values\n",
    "w = np.linalg.inv(matrix_original.T @ matrix_original) @ matrix_original.T @ y\n",
    "display(w)\n",
    "\n",
    "# determine the set of parameters for the new features\n",
    "\n",
    "v = np.linalg.inv(matrix_new.T @ matrix_new) @ matrix_new.T @ y\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1494551172773669"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.1494551172778526"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show that the quality of the model is the same before and after\n",
    "\n",
    "def mse(target, predictions):\n",
    "    return((target - predictions)**2).mean()\n",
    "\n",
    "pred_original = matrix_original @ w\n",
    "display(mse(y, pred_original))\n",
    "\n",
    "pred_new = matrix_new @ v\n",
    "display(mse(y, pred_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's observed that the two mse metrics are practically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the weight vectors from MSE minimums for these models related?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.43854686e-02,  2.33356224e-02, -1.17739038e-05, -4.55168125e-02])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ths is what we are comparing against\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.43852530e-02,  2.33356184e-02, -1.17738878e-05, -4.55167757e-02])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We found that w is equivalent to the following\n",
    "\n",
    "B@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.54841463e-05,  9.01471566e-05,  3.56435998e-05, -7.15728779e-05])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-6.54845156e-05,  9.01472933e-05,  3.56437333e-05, -7.15728238e-05])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, we want to find a formula in terms of w so that v can be replaced\n",
    "\n",
    "display(v)\n",
    "display(w@np.linalg.inv(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we showed that v can be expressed in terms of w. Now, we are ready to move on to step3 which is to state an algorithm for data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State an algorithm for data transformation to solve the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1686.06778671, 1255.37879644, 1245.09216   , 1278.73772363],\n",
       "       [1255.37879644, 1691.51482931, 1252.25039352, 1279.49217018],\n",
       "       [1245.09216   , 1252.25039352, 1651.48707909, 1260.6693517 ],\n",
       "       [1278.73772363, 1279.49217018, 1260.6693517 , 1705.35412254]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0018012 , -0.00050437, -0.00053569, -0.00057618],\n",
       "       [-0.00050437,  0.00180493, -0.00055843, -0.0005632 ],\n",
       "       [-0.00053569, -0.00055843,  0.00185075, -0.00054749],\n",
       "       [-0.00057618, -0.0005632 , -0.00054749,  0.00184571]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note both B and B inverse are symmetric\n",
    "\n",
    "display(B)\n",
    "display(np.linalg.inv(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v_min = w_min dot the inverse of a random matrix \n",
    "- MSE(X*A*v_min, y) =  MSE(X*A*w_min*A^-1, y) = MSE(X*A*A^-1*w_min, y) = MSE(X*w_min, y)\n",
    "- Since both A and A^-1 are symmetric, order does not matter when multiplying with a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain why the linear regression quality won't change based on the proof above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.267534130756125e-06"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's examine dot product of w and v, ths gives us insight about the relation of the two vectors in terms of how similar\n",
    "\n",
    "v@w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We noticed that both w and v are non-zero vectors but their dot product is a almost zero scalar. This indicates that the angle (theta) between the two vectors in a cosine is 0. \n",
    "- Please note that w dot v is equivalent to the magnitidue of vector w multiply the magnitude of vector v then multiply cosine theta. The only way that we can get zero is the cosine theta is 0 because both vectors has non-zero magnitude.\n",
    "- The result of zero means the vectors are perpendicular to each other.\n",
    "- With all said, having two vectors that are orthogonal to each other means that when one of such vectors is multiplied with the feature matrix, it spans the entire matrix and \"rotate\" it to another direction rather than scaling the original martrix. This is why our linear regression quality does not change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890165298678149"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviewer's code for calculation of angle cos between two vectors\n",
    "\n",
    "(v@w)/(np.linalg.norm(v)*np.linalg.norm(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "No, unfortunately this is not a reason. Please look at sizes of your vectors w and v. They are very small. That is why the dot product is almost zero. You chosed $B$ with big values so the vectov v is almost close to zero. If you take instead of B it inverse or some other invertible matrix with smaller values you obtain another result.</div>\n",
    "\n",
    "Here it is better to compare two formulas:\n",
    "\n",
    "$$\n",
    "w = (X^T * X)^{-1} * X^T * y\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "v = ((X*B)^T * X*B)^{-1} * (X*B)^T * y\n",
    "$$\n",
    "\n",
    "ant try to find some connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited:\n",
    "\n",
    "Thanks for the hint, to explain why the regression quality won't change, let's actually take one step back and re-state some of the apparent relations that are needed. We would need the following in order to answer this question:\n",
    "- First we know that w = arg_w min MSE(Xw, y)\n",
    "- To answer why the regression quality doesn't change we need to answer the question why MSE(Xw, y) = MSE(XBv, y)\n",
    "- From the previous step, we discovered that v = w * B_inverse = B_inverse * w, we can further prove this is true since B is symmetric and when a symmetric matrix is multiplied by a vector, the position of is vector does not matter.\n",
    "- Applying this equation to the MSE assessment we found that even though feature matrix X is multiplied with some invertible B\n",
    "- This effect can ultimately be reset because when X * B * B_inverse * w, we will get back X * Identity * w as an equivelant.\n",
    "- This makes MSE(Xw, y) = MSE(XBv, y) which indicates that the quality of the regression won't change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "OK, your reasoning looks correct, but actually this fact is correct for general case, when B isn't symmetric. Try to think how to set this up. It is a good exersize.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program your algorithm using matrix operations. Make sure that the quality of linear regression from sklearn is the same before and after transformation. Use the R2 metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30322655304822976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.30322655304596546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We previous constructed the predictions using matrix operations, now we will use them\n",
    "\n",
    "display(r2_score(y, pred_original))\n",
    "display(r2_score(y, pred_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's observed that the two r2 metrics are practically the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
